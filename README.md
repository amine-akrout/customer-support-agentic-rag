# ğŸ¤– Customer Support Agentic RAG

**An intelligent customer support system leveraging LangGraph and LangChain for Retrieval-Augmented Generation (RAG) with agent-like behavior to deliver accurate, context-aware responses.**

---

## ğŸš€ Project Overview

This project implements a **sophisticated RAG-based customer support system** that combines the power of **LangGraph for workflow orchestration** and **LangChain for LLM interactions**. The system provides intelligent, context-aware responses to customer queries through a multi-stage validation and retrieval pipeline.

Built with **FastAPI, FAISS, LangGraph, and Ollama**, this system efficiently processes customer support queries while maintaining high accuracy and safety standards through comprehensive validation checks.

---

## âœ¨ Key Features

âœ… **Intelligent Workflow Orchestration** â€“ LangGraph-powered pipeline for sophisticated query processing
âœ… **Advanced Document Retrieval** â€“ FAISS vector store for efficient semantic search
âœ… **Multi-Stage Validation** â€“ Comprehensive quality checks at each step
âœ… **Local LLM Support** â€“ Integration with Ollama for on-premise deployment
âœ… **Content Safety** â€“ LLM Guard implementation for safe responses
âœ… **Efficient Data Processing** â€“ Polars-based data preprocessing
âœ… **API-First Design** â€“ FastAPI backend for scalable deployment

---

## ğŸ—ï¸ Tech Stack

| Category | Tools Used |
|----------|------------|
| **Programming** | `Python 3.9+` |
| **LLM Integration** | `LangChain`, `Ollama`, `OpenAI API (optional)` |
| **Vector Search** | `FAISS` |
| **Workflow Orchestration** | `LangGraph` |
| **Backend Framework** | `FastAPI` |
| **Data Processing** | `Polars` |
| **Safety & Validation** | `LLM Guard` |
| **Deployment** | `Docker`, `Docker Compose` |

---

## ğŸ”§ System Architecture

The system follows a sophisticated agentic workflow with six main components:

1. **Question Validation**
   - Input safety checks
   - Token limit verification
   - Toxicity detection

2. **Topic Classification**
   - Customer support relevance verification
   - Query categorization

3. **Document Retrieval**
   - FAISS-powered semantic search
   - Context gathering

4. **Document Grading**
   - Relevance scoring
   - Context validation

5. **Answer Generation**
   - Context-aware response generation
   - Local or cloud LLM integration

6. **Answer Validation**
   - Output quality assessment
   - Safety verification

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ indexes/          # FAISS index storage
â”‚   â””â”€â”€ customer_care_emails.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/             # FastAPI application
â”‚   â”œâ”€â”€ graph/           # LangGraph workflow components
â”‚   â”‚   â”œâ”€â”€ answer_check_node.py
â”‚   â”‚   â”œâ”€â”€ answer_node.py
â”‚   â”‚   â”œâ”€â”€ docs_grader_node.py
â”‚   â”‚   â”œâ”€â”€ graph.py
â”‚   â”‚   â”œâ”€â”€ question_check_node.py
â”‚   â”‚   â”œâ”€â”€ retriever_node.py
â”‚   â”‚   â”œâ”€â”€ state.py
â”‚   â”‚   â”œâ”€â”€ topic_check_node.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”œâ”€â”€ static/          # Frontend assets
â”‚   â””â”€â”€ indexing/        # Data preprocessing and indexing
â”œâ”€â”€ tests/               # Test cases
â”œâ”€â”€ Dockerfile           # Docker file
â””â”€â”€ docker-compose.yml   # Docker configuration
```

---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Prerequisites

Before you begin, ensure you have:
- Python 3.9 or higher
- Docker (optional)
- [Ollama](https://ollama.ai/) installed (for local LLM support)
- OpenAI API key (optional, for cloud LLM)

### 2ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/amine-akrout/customer-support-agentic-rag.git
cd customer-support-agentic-rag
```

### 3ï¸âƒ£ Environment Setup

Create and activate a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: .\venv\Scripts\activate
```

Install dependencies:
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configuration

Create a `.env` file with your settings:
```env
OPENAI_API_KEY=your_api_key_here  # Optional
LANGCHAIN_API_KEY=your_api_key_here # Optional
LANGCHAIN_TRACING_V2= true # Optional
LANGCHAIN_PROJECT=your_project_id_here # Optional

```

---

## ğŸš€ Usage

### Local Development

1. **Preprocess and Index Data**
```bash
python -m src.indexing.preprocess
```

2. **Start the API Server**
```bash
uvicorn src.main:app --reload
```

3. Access the API at `http://localhost:8000`

### Docker Deployment

1. **Build and Start Containers**
```bash
docker-compose up --build
```

2. Access the API at `http://localhost:8000`

---

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/answer` | Submit question and get response |
| `GET` | `/health` | Check API health status |

Example request:
```json
{
  "question": "How do I return a damaged product?"
}
```

---

## ğŸ”„ Workflow Process

The system follows this process for each query:

1. **Input Processing**
   - Question validation
   - Safety checks
   - Topic classification

2. **Context Retrieval**
   - Document search
   - Relevance scoring
   - Context selection

3. **Response Generation**
   - Answer formulation
   - Quality validation
   - Safety verification

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/improvement`)
3. Make your changes
4. Commit (`git commit -am 'Add new feature'`)
5. Push (`git push origin feature/improvement`)
6. Create a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [LangChain](https://github.com/hwchase17/langchain) - LLM framework
- [LangGraph](https://github.com/hwchase17/langgraph) - Workflow orchestration
- [FastAPI](https://fastapi.tiangolo.com/) - API framework
- [FAISS](https://github.com/facebookresearch/faiss) - Vector similarity search
- [Ollama](https://ollama.ai/) - Local LLM support

---

## â­ Star This Repo!

If you find this project useful, please consider giving it a star! ğŸŒŸ

---

## ğŸ“© Contact

For questions or feedback, please open an issue in the repository.

---
